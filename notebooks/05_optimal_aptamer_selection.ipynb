{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Aptamer Selection\n",
    "\n",
    "This notebook selects optimal aptamers for each target molecule based on binding affinity, specificity, and structural stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to the path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.binding_affinity import BindingAffinityPredictor\n",
    "from src.models.cross_reactivity import CrossReactivityAnalyzer\n",
    "from src.aptamer_selection.selector import AptamerSelector\n",
    "from src.aptamer_selection.specificity_optimizer import AptamerOptimizer\n",
    "from src.visualization.plot_utils import AptamerVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cross-reactivity analysis results or feature-enriched data\n",
    "crossreact_path = '../data/processed/cross_reactivity_analysis.csv'\n",
    "\n",
    "if os.path.exists(crossreact_path):\n",
    "    df = pd.read_csv(crossreact_path)\n",
    "    print(f\"Loaded cross-reactivity analysis results: {len(df)} rows\")\n",
    "else:\n",
    "    # Try feature-enriched data\n",
    "    feature_path = '../data/processed/aptamers_with_features.csv'\n",
    "    if os.path.exists(feature_path):\n",
    "        df = pd.read_csv(feature_path)\n",
    "        print(f\"Loaded feature-enriched data: {len(df)} rows\")\n",
    "    else:\n",
    "        # Try preprocessed data\n",
    "        processed_path = '../data/processed/preprocessed_aptamers.csv'\n",
    "        if os.path.exists(processed_path):\n",
    "            df = pd.read_csv(processed_path)\n",
    "            print(f\"Loaded preprocessed data: {len(df)} rows\")\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "            print(\"No data available. Please run the previous notebooks first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if required columns are present\n",
    "if len(df) > 0:\n",
    "    if 'Target_Name' not in df.columns:\n",
    "        print(\"WARNING: No 'Target_Name' column found. Aptamer selection requires target information.\")\n",
    "    else:\n",
    "        print(f\"Found {df['Target_Name'].nunique()} unique targets in the dataset\")\n",
    "        print(df['Target_Name'].value_counts())\n",
    "        \n",
    "    seq_col = 'Sequence' if 'Sequence' in df.columns else 'sequence'\n",
    "    if seq_col not in df.columns:\n",
    "        print(\"WARNING: No sequence column found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously trained models\n",
    "binding_model = BindingAffinityPredictor()\n",
    "binding_model_path = '../models/binding_affinity_model.pkl'\n",
    "\n",
    "if os.path.exists(binding_model_path):\n",
    "    try:\n",
    "        binding_model.load_model(binding_model_path)\n",
    "        print(f\"Loaded binding affinity model from {binding_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading binding affinity model: {str(e)}\")\n",
    "else:\n",
    "    print(f\"No binding affinity model found at {binding_model_path}\")\n",
    "\n",
    "cross_reactivity_model = CrossReactivityAnalyzer()\n",
    "cr_model_path = '../models/cross_reactivity_model.pkl'\n",
    "\n",
    "if os.path.exists(cr_model_path):\n",
    "    try:\n",
    "        cross_reactivity_model.load_model(cr_model_path)\n",
    "        print(f\"Loaded cross-reactivity model from {cr_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading cross-reactivity model: {str(e)}\")\n",
    "else:\n",
    "    print(f\"No cross-reactivity model found at {cr_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Aptamer Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and initialize the aptamer selector\n",
    "selector_config = {\n",
    "    'specificity_weight': 0.6,         # Weight for specificity in selection score\n",
    "    'binding_affinity_weight': 0.4,    # Weight for binding affinity in selection score\n",
    "    'structural_stability_weight': 0.3, # Weight for structural stability in selection score\n",
    "    'min_binding_score': 0.7,          # Minimum binding score threshold\n",
    "    'max_cross_reactivity': 0.2        # Maximum acceptable cross-reactivity\n",
    "}\n",
    "\n",
    "selector = AptamerSelector(selector_config)\n",
    "\n",
    "# Set the models if they were successfully loaded\n",
    "if hasattr(binding_model, 'model') and binding_model.model is not None:\n",
    "    selector.binding_model = binding_model\n",
    "    \n",
    "if hasattr(cross_reactivity_model, 'model') and cross_reactivity_model.model is not None:\n",
    "    selector.cross_reactivity_model = cross_reactivity_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Target Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target molecules of interest\n",
    "if 'Target_Name' in df.columns:\n",
    "    all_targets = df['Target_Name'].unique().tolist()\n",
    "    print(f\"Available targets in the dataset: {all_targets}\")\n",
    "else:\n",
    "    # Default targets if none in the dataset\n",
    "    all_targets = ['fentanyl', 'methamphetamine', 'benzodiazepine', 'xylazine', 'nitazene']\n",
    "    print(f\"Using default targets: {all_targets}\")\n",
    "\n",
    "# Allow user to select specific targets\n",
    "targets_of_interest = all_targets\n",
    "print(f\"\\nSelecting aptamers for targets: {targets_of_interest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Optimal Aptamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select optimal aptamers for each target\n",
    "if len(df) > 0:\n",
    "    num_aptamers_per_target = 5  # Number of aptamers to select per target\n",
    "    \n",
    "    print(f\"Selecting {num_aptamers_per_target} optimal aptamers for each target...\")\n",
    "    selected_aptamers = selector.select_optimal_aptamers(\n",
    "        df, targets_of_interest, n_per_target=num_aptamers_per_target\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSelected {len(selected_aptamers)} aptamers in total:\")\n",
    "    if 'Target_Name' in selected_aptamers.columns:\n",
    "        print(selected_aptamers['Target_Name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the selected aptamers\n",
    "if 'selected_aptamers' in locals() and len(selected_aptamers) > 0:\n",
    "    # Define columns to display\n",
    "    display_cols = ['Target_Name', 'selection_score', 'specificity_score']\n",
    "    \n",
    "    # Add sequence column if available\n",
    "    seq_col = 'Sequence' if 'Sequence' in selected_aptamers.columns else 'sequence'\n",
    "    if seq_col in selected_aptamers.columns:\n",
    "        display_cols = [seq_col] + display_cols\n",
    "    \n",
    "    # Add binding column if available\n",
    "    binding_col = None\n",
    "    for col in selected_aptamers.columns:\n",
    "        if 'binding' in col.lower() or 'affinity' in col.lower():\n",
    "            binding_col = col\n",
    "            break\n",
    "    \n",
    "    if binding_col:\n",
    "        display_cols.append(binding_col)\n",
    "    \n",
    "    # Add structural stability if available\n",
    "    if 'stability_score' in selected_aptamers.columns:\n",
    "        display_cols.append('stability_score')\n",
    "    \n",
    "    # Display the selected aptamers grouped by target\n",
    "    for target in targets_of_interest:\n",
    "        target_aptamers = selected_aptamers[selected_aptamers['Target_Name'] == target]\n",
    "        \n",
    "        if len(target_aptamers) > 0:\n",
    "            print(f\"\\n--- Selected aptamers for {target} ---\")\n",
    "            display(target_aptamers[display_cols].sort_values('selection_score', ascending=False))\n",
    "        else:\n",
    "            print(f\"\\nNo aptamers selected for {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Aptamer Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the quality of selected aptamers\n",
    "if 'selected_aptamers' in locals() and len(selected_aptamers) > 0:\n",
    "    verified_aptamers = selector.verify_aptamer_quality(selected_aptamers, targets_of_interest)\n",
    "    \n",
    "    # Display the additional quality metrics\n",
    "    quality_cols = ['Target_Name', 'quality_category', 'g4_potential', 'homopolymer_risk', 'estimated_tm']\n",
    "    \n",
    "    # Add sequence column if available\n",
    "    if seq_col in verified_aptamers.columns:\n",
    "        quality_cols = [seq_col] + quality_cols\n",
    "    \n",
    "    print(\"Verified aptamer quality metrics:\")\n",
    "    display(verified_aptamers[quality_cols])\n",
    "    \n",
    "    # Count aptamers by quality category\n",
    "    if 'quality_category' in verified_aptamers.columns:\n",
    "        quality_counts = verified_aptamers['quality_category'].value_counts()\n",
    "        print(\"\\nAptamers by quality category:\")\n",
    "        print(quality_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Selected Aptamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize binding affinity vs specificity for selected aptamers\n",
    "if 'verified_aptamers' in locals() and len(verified_aptamers) > 0:\n",
    "    # Create visualizer\n",
    "    visualizer = AptamerVisualizer()\n",
    "    \n",
    "    # Plot binding vs specificity\n",
    "    visualizer.plot_binding_vs_specificity(verified_aptamers, color_by_target=True)\n",
    "    \n",
    "    # Create dashboard\n",
    "    visualizer.create_dashboard(verified_aptamers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize structures of a few selected aptamers\n",
    "if 'verified_aptamers' in locals() and len(verified_aptamers) > 0:\n",
    "    if 'predicted_structure' in verified_aptamers.columns and seq_col in verified_aptamers.columns:\n",
    "        # Get the top aptamer for each target\n",
    "        top_aptamers = []\n",
    "        for target in targets_of_interest:\n",
    "            target_aptamers = verified_aptamers[verified_aptamers['Target_Name'] == target]\n",
    "            if len(target_aptamers) > 0:\n",
    "                top_aptamer = target_aptamers.iloc[0]\n",
    "                top_aptamers.append(top_aptamer)\n",
    "        \n",
    "        # Visualize the structures\n",
    "        for aptamer in top_aptamers:\n",
    "            visualizer.plot_structure_visualization(\n",
    "                aptamer[seq_col],\n",
    "                aptamer['predicted_structure'],\n",
    "                title=f\"Structure for {aptamer['Target_Name']} aptamer\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Selected Aptamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sequence similarity between selected aptamers\n",
    "if 'verified_aptamers' in locals() and len(verified_aptamers) > 0 and seq_col in verified_aptamers.columns:\n",
    "    # Limit to a manageable number of sequences for visualization\n",
    "    if len(verified_aptamers) > 20:\n",
    "        # Take top 3-4 for each target\n",
    "        sample_aptamers = []\n",
    "        for target in targets_of_interest:\n",
    "            target_aptamers = verified_aptamers[verified_aptamers['Target_Name'] == target]\n",
    "            if len(target_aptamers) > 0:\n",
    "                sample_aptamers.append(target_aptamers.head(min(4, len(target_aptamers))))\n",
    "        \n",
    "        sample_df = pd.concat(sample_aptamers, ignore_index=True)\n",
    "    else:\n",
    "        sample_df = verified_aptamers\n",
    "    \n",
    "    # Create sequence labels\n",
    "    labels = [f\"{row['Target_Name']} #{i+1}\" for i, (_, row) in enumerate(sample_df.iterrows())]\n",
    "    \n",
    "    # Visualize sequence similarity\n",
    "    visualizer.plot_sequence_similarity_heatmap(\n",
    "        sample_df[seq_col].tolist(),\n",
    "        labels=labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare features across targets\n",
    "if 'verified_aptamers' in locals() and len(verified_aptamers) > 0 and 'Target_Name' in verified_aptamers.columns:\n",
    "    # Select features to compare\n",
    "    features_to_compare = [\n",
    "        'gc_content' if 'gc_content' in verified_aptamers.columns else 'GC_Content',\n",
    "        'length',\n",
    "        'specificity_score',\n",
    "        'stability_score' if 'stability_score' in verified_aptamers.columns else None,\n",
    "        'estimated_tm' if 'estimated_tm' in verified_aptamers.columns else None\n",
    "    ]\n",
    "    \n",
    "    # Filter out None values\n",
    "    features_to_compare = [f for f in features_to_compare if f is not None and f in verified_aptamers.columns]\n",
    "    \n",
    "    if features_to_compare:\n",
    "        # Create multi-panel plot\n",
    "        fig, axes = plt.subplots(1, len(features_to_compare), figsize=(4 * len(features_to_compare), 5))\n",
    "        \n",
    "        for i, feature in enumerate(features_to_compare):\n",
    "            if len(features_to_compare) == 1:\n",
    "                ax = axes\n",
    "            else:\n",
    "                ax = axes[i]\n",
    "                \n",
    "            sns.boxplot(x='Target_Name', y=feature, data=verified_aptamers, ax=ax)\n",
    "            ax.set_title(f'{feature} by Target')\n",
    "            ax.set_xlabel('Target')\n",
    "            ax.set_ylabel(feature)\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Aptamers (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize aptamers to improve specificity (optional - can be time-consuming)\n",
    "run_optimization = False  # Set to True to run optimization\n",
    "\n",
    "if run_optimization and 'verified_aptamers' in locals() and len(verified_aptamers) > 0:\n",
    "    # Initialize optimizer\n",
    "    optimizer = AptamerOptimizer({\n",
    "        'optimization_iterations': 50,  # Higher values for better results (1000+ for production)\n",
    "        'population_size': 50,          # Higher values for better results (200+ for production)\n",
    "        'mutation_rate': 0.05,\n",
    "        'crossover_rate': 0.8,\n",
    "        'specificity_weight': 0.7,      # Emphasize specificity in optimization\n",
    "        'binding_affinity_weight': 0.3\n",
    "    })\n",
    "    \n",
    "    # Set the models\n",
    "    if hasattr(binding_model, 'model') and binding_model.model is not None:\n",
    "        optimizer.binding_model = binding_model\n",
    "        \n",
    "    if hasattr(cross_reactivity_model, 'model') and cross_reactivity_model.model is not None:\n",
    "        optimizer.cross_reactivity_model = cross_reactivity_model\n",
    "    \n",
    "    print(\"Starting aptamer optimization...\")\n",
    "    optimized_aptamers = optimizer.run_parallel_optimization(\n",
    "        verified_aptamers,\n",
    "        targets=targets_of_interest,\n",
    "        num_optimized=3  # Number of optimized aptamers per target\n",
    "    )\n",
    "    \n",
    "    print(f\"Optimization complete. Generated {len(optimized_aptamers)} optimized aptamers.\")\n",
    "    \n",
    "    # Display optimized aptamers\n",
    "    display_cols = ['Target_Name', 'optimization_fitness', 'specificity_score']\n",
    "    \n",
    "    if seq_col in optimized_aptamers.columns:\n",
    "        display_cols = [seq_col] + display_cols\n",
    "    \n",
    "    if 'predicted_affinity' in optimized_aptamers.columns:\n",
    "        display_cols.append('predicted_affinity')\n",
    "    \n",
    "    print(\"\\nOptimized aptamers:\")\n",
    "    display(optimized_aptamers[display_cols].sort_values(['Target_Name', 'optimization_fitness'], ascending=[True, False]))\n",
    "else:\n",
    "    print(\"Skipping aptamer optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Original vs Optimized Aptamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs optimized aptamers (if optimization was run)\n",
    "if run_optimization and 'optimized_aptamers' in locals() and len(optimized_aptamers) > 0:\n",
    "    # Compare specificity scores\n",
    "    orig_specificity = verified_aptamers.groupby('Target_Name')['specificity_score'].mean()\n",
    "    opt_specificity = optimized_aptamers.groupby('Target_Name')['specificity_score'].mean()\n",
    "    \n",
    "    # Calculate improvement\n",
    "    targets = set(orig_specificity.index) | set(opt_specificity.index)\n",
    "    \n",
    "    comparison_data = []\n",
    "    for target in targets:\n",
    "        orig_score = orig_specificity.get(target, np.nan)\n",
    "        opt_score = opt_specificity.get(target, np.nan)\n",
    "        \n",
    "        if not np.isnan(orig_score) and not np.isnan(opt_score):\n",
    "            improvement = (opt_score - orig_score) / orig_score * 100\n",
    "        else:\n",
    "            improvement = np.nan\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Target': target,\n",
    "            'Original_Specificity': orig_score,\n",
    "            'Optimized_Specificity': opt_score,\n",
    "            'Improvement_Percent': improvement\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(\"Specificity improvement from optimization:\")\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Visualize the improvement\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x = range(len(comparison_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar([i - width/2 for i in x], comparison_df['Original_Specificity'], width, label='Original')\n",
    "    plt.bar([i + width/2 for i in x], comparison_df['Optimized_Specificity'], width, label='Optimized')\n",
    "    \n",
    "    plt.xlabel('Target')\n",
    "    plt.ylabel('Average Specificity Score')\n",
    "    plt.title('Specificity Improvement from Optimization')\n",
    "    plt.xticks(x, comparison_df['Target'])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save selected aptamers\n",
    "if 'verified_aptamers' in locals() and len(verified_aptamers) > 0:\n",
    "    output_dir = '../results'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save selected aptamers\n",
    "    selected_path = os.path.join(output_dir, 'selected_aptamers.csv')\n",
    "    verified_aptamers.to_csv(selected_path, index=False)\n",
    "    print(f\"Selected aptamers saved to {selected_path}\")\n",
    "    \n",
    "    # Save optimized aptamers if available\n",
    "    if run_optimization and 'optimized_aptamers' in locals() and len(optimized_aptamers) > 0:\n",
    "        optimized_path = os.path.join(output_dir, 'optimized_aptamers.csv')\n",
    "        optimized_aptamers.to_csv(optimized_path, index=False)\n",
    "        print(f\"Optimized aptamers saved to {optimized_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary report of the final aptamers\n",
    "if 'verified_aptamers' in locals() and len(verified_aptamers) > 0:\n",
    "    # Create a report DataFrame\n",
    "    report_data = []\n",
    "    \n",
    "    for target in targets_of_interest:\n",
    "        target_aptamers = verified_aptamers[verified_aptamers['Target_Name'] == target]\n",
    "        \n",
    "        if len(target_aptamers) > 0:\n",
    "            # Get top 3 aptamers\n",
    "            top_aptamers = target_aptamers.sort_values('selection_score', ascending=False).head(3)\n",
    "            \n",
    "            for i, (_, aptamer) in enumerate(top_aptamers.iterrows(), 1):\n",
    "                aptamer_seq = aptamer[seq_col] if seq_col in aptamer else \"N/A\"\n",
    "                selection_score = aptamer.get('selection_score', \"N/A\")\n",
    "                specificity = aptamer.get('specificity_score', \"N/A\")\n",
    "                binding = aptamer.get('predicted_affinity', aptamer.get('binding_affinity', \"N/A\"))\n",
    "                stability = aptamer.get('stability_score', \"N/A\")\n",
    "                quality = aptamer.get('quality_category', \"N/A\")\n",
    "                \n",
    "                # Add to report\n",
    "                report_data.append({\n",
    "                    'Target': target,\n",
    "                    'Rank': i,\n",
    "                    'Aptamer_Sequence': aptamer_seq,\n",
    "                    'Selection_Score': selection_score,\n",
    "                    'Specificity': specificity,\n",
    "                    'Binding_Affinity': binding,\n",
    "                    'Structural_Stability': stability,\n",
    "                    'Quality': quality\n",
    "                })\n",
    "    \n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    \n",
    "    # Save the report\n",
    "    report_path = os.path.join(output_dir, 'aptamer_selection_report.csv')\n",
    "    report_df.to_csv(report_path, index=False)\n",
    "    print(f\"Selection report saved to {report_path}\")\n",
    "    \n",
    "    # Display the report\n",
    "    print(\"\\nAptamer Selection Report:\")\n",
    "    display(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Selected Aptamer Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final selected aptamer sequences for each target\n",
    "if 'verified_aptamers' in locals() and len(verified_aptamers) > 0 and seq_col in verified_aptamers.columns:\n",
    "    print(\"Final Selected Aptamer Sequences:\\n\")\n",
    "    \n",
    "    for target in targets_of_interest:\n",
    "        target_aptamers = verified_aptamers[verified_aptamers['Target_Name'] == target]\n",
    "        \n",
    "        if len(target_aptamers) > 0:\n",
    "            # Sort by selection score\n",
    "            top_aptamers = target_aptamers.sort_values('selection_score', ascending=False)\n",
    "            \n",
    "            print(f\"--- {target.upper()} ---\")\n",
    "            for i, (_, aptamer) in enumerate(top_aptamers.iterrows(), 1):\n",
    "                print(f\"Aptamer #{i}: {aptamer[seq_col]}\")\n",
    "                if 'selection_score' in aptamer:\n",
    "                    print(f\"   Selection Score: {aptamer['selection_score']:.4f}\")\n",
    "                if 'specificity_score' in aptamer:\n",
    "                    print(f\"   Specificity: {aptamer['specificity_score']:.4f}\")\n",
    "                if 'quality_category' in aptamer:\n",
    "                    print(f\"   Quality: {aptamer['quality_category']}\")\n",
    "                print()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Based on our selection process, we have identified optimal aptamers for each of our target adulterants:\n",
    "\n",
    "1. **Fentanyl**: [Fill in after running the notebook]\n",
    "\n",
    "2. **Methamphetamine**: [Fill in after running the notebook]\n",
    "\n",
    "3. **Benzodiazepine**: [Fill in after running the notebook]\n",
    "\n",
    "4. **Xylazine**: [Fill in after running the notebook]\n",
    "\n",
    "5. **Nitazene**: [Fill in after running the notebook]\n",
    "\n",
    "These aptamers were selected based on a balanced consideration of binding affinity, specificity (minimal cross-reactivity), and structural stability, making them promising candidates for use in our test strips."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
